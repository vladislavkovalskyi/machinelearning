Ниже приведён пример набора вопросов (часть из них взяты из методички, часть — сформулированы дополнительно), а также ответы на них, опираясь на типичное решение задачи классификации (например, на датасете Adult). Формулировки можно подстроить под конкретные требования вашей методички.

1. Как убедились, что в данных нет пропусков?

Вопрос (из методички, пункт 1): «Переконайтеся, що у наборі даних немає пропусків».
Ответ:
	•	Изначально в файлах adult.data и adult.test пропуски часто обозначены символом ?.
	•	Мы считали датафрейм, заменили ? на NaN и проверили наличие пропусков методом df.isnull().sum().
	•	В случае обнаружения пропусков в категориальных столбцах — заполняли их модой (чаще всего встречающимся значением), а в числовых — медианой. После этого итоговых пропусков не осталось.

2. Как закодировали качественные (категориальные) признаки?

Вопрос (из методички, пункт 1): «Бінаризуйте або закодуйте якісні ознаки (залежно від того, чи вони номінальні чи порядкові)».
Ответ:
	•	В датасете Adult встречаются номинальные категориальные признаки (например, workclass, occupation, native-country и т. д.).
	•	Для кодирования большинства категориальных признаков применили One-Hot-Encoding (через pd.get_dummies), так как они не имеют упорядоченной структуры.
	•	Целевую переменную income (два класса: <=50K и >50K) перевели в 0/1 с помощью LabelEncoder.

3. Выполняли ли вы масштабирование количественных признаков и зачем?

Вопрос (частично из методички, пункт 1): «Масштабування кількісних ознак є необов’язковим, але його можна виконати».
Ответ:
	•	Количественные признаки (age, fnlwgt, education-num, capital-gain, capital-loss, hours-per-week) могут сильно отличаться по своим диапазонам.
	•	Мы выполнили масштабирование (MinMaxScaler или StandardScaler — в зависимости от решения) для того, чтобы
	1.	ускорить и стабилизировать сходимость алгоритмов (например, при логистической регрессии),
	2.	корректно работать с методами, чувствительными к масштабам (k-NN, SVM и пр.).

4. Сбалансированы ли классы в задаче? Нужно ли проводить балансировку?

Вопрос (из методички, пункт 2): «Визначте, чи збалансовані класи».
Ответ:
	•	В датасете Adult примерно 75% объектов относятся к классу <=50K и 25% — к >50K. Это означает некоторый дисбаланс, но он не слишком критичный.
	•	Специальных методов (oversampling, undersampling) мы не применяли, однако учитываем это при выборе метрик: помимо Accuracy, используем AUC-ROC, Precision, Recall и F1-score.

5. Какие метрики выбраны для оценки качества классификации и почему?

Вопрос (из методички, пункт 3): «Оберіть одну або кілька метрик для оцінки якості класифікації».
Ответ:
	•	Основная метрика — AUC-ROC, так как она хорошо показывает способность модели различать два класса и менее чувствительна к несбалансированности.
	•	Дополнительно смотрим Accuracy, Precision, Recall и F1 для более детального анализа.

6. Почему нужно разделять данные на обучающую и тестовую выборки? Какое соотношение выбрано?

Вопрос (из методички, пункт 4): «Розділіть набір даних на навчальну та тестову вибірки…».
Ответ:
	•	Разделение необходимо, чтобы проверить обобщающую способность модели на «неизвестных» данных и избежать «подгонки» под всю выборку.
	•	Обычно используют соотношение 80% / 20% или 70% / 30% (в зависимости от размера датасета). В нашем случае выбрано 80% на обучение и 20% на тест.
	•	При этом для сохранения пропорций классов указываем stratify=y в train_test_split.

7. Как обучили логистическую регрессию без регуляризации? Возникли ли проблемы?

Вопрос (из методички, пункт 5): «Навчіть модель логістичної регресії без регуляризації…».
Ответ:
	•	В sklearn по умолчанию используется L2-регуляризация. Чтобы отключить её, в LogisticRegression задаём параметр penalty='none'.
	•	Иногда без регуляризации может возникать проблема с сходимостью, поэтому мы настраиваем solver, например, solver='lbfgs' или solver='saga'.
	•	Обучение прошло успешно, модель построена как бинарная, поскольку у нас два класса (<=50K и >50K).
	•	Количество параметров (весов) равно числу признаков + 1 (свободный член). После One-Hot-Encoding признаков может стать значительно больше, поэтому весов тоже много.

8. Как оценили качество модели без регуляризации? Были ли признаки переобучения?

Вопрос (из методички, пункт 6): «Розрахуйте обрані метрики якості… Оцініть ризик перенавчання».
Ответ:
	•	На train данные модель давала, например, Accuracy ~ 85–86%, AUC-ROC ~ 0.90+. На test — Accuracy ~ 84–85%, AUC-ROC ~ 0.89–0.90 (точные цифры зависят от конкретного запуска).
	•	Разница метрик на тренировке и тесте небольшая, значит переобучение не слишком сильное. Однако кое-какие весовые коэффициенты без регуляризации могут быть слишком большими, что намекает на риск переобучения.

9. Зачем проводили кросс-валидацию и какие результаты получили?

Вопрос (из методички, пункт 7): «Використайте k-кратну перехресну перевірку…».
Ответ:
	•	Кросс-валидация помогает оценить модель на нескольких разных разбиениях, получая более стабильную оценку.
	•	Мы использовали, к примеру, 5-кратную (5-fold) кросс-валидацию через cross_val_score с метрикой AUC-ROC. Среднее значение AUC получалось около ~0.89–0.90, что сопоставимо с результатом на тестовой выборке.
	•	При увеличении числа фолдов точность оценки может слегка повышаться, но время вычислений растёт.

10. Как обучали логистическую регрессию с регуляризацией и как подбирали C?

Вопрос (из методички, пункт 8): «Використайте регуляризацію (L2 або L1)… Підберіть оптимальне значення параметра регуляризації С…».
Ответ:
	•	С регуляризацией (L2 по умолчанию) мы подбирали параметр C (чем он меньше, тем сильнее регуляризация).
	•	Использовали GridSearchCV, перебирая значения, например, [0.01, 0.1, 1, 10, 100].
	•	Лучшими по метрике AUC-ROC оказались значения C в диапазоне 1 или 10 (зависит от конкретного решения).
	•	Тестовая выборка не участвовала в подборе гиперпараметров — только обучающая (с внутренней кросс-валидацией).

11. Помогла ли регуляризация снизить переобучение?

Вопрос (из методички, пункт 9): «Поясніть, чи допомогла регуляризація зменшити перенавчання».
Ответ:
	•	При добавлении L2-регуляризации веса модели стали более «сжатыми», а разброс метрик на кросс-валидации слегка уменьшился.
	•	Переобучение, оцененное разницей метрик на train и test, стало меньше, а итоговый AUC-ROC на тесте часто немного выше.

12. Проводился ли отбор признаков?

Вопрос (из методички, пункт 10, опционально): «Спробуйте здійснити відбір інформативних ознак…».
Ответ:
	•	В базовом решении мы не делали явного отбора признаков (кроме использования регуляризации).
	•	При желании можно применить L1-регуляризацию (которая «обнуляет» некоторые коэффициенты), или методы SelectKBest, RFE и т. д.
	•	Это опционально, но иногда даёт более интерпретируемую модель без заметной потери качества.

13. Какой дополнительный классификатор обучался и как оценили его качество?

Вопрос (из методички, пункт 11): «Оберіть інший класифікатор…».
Ответ:
	•	В качестве второго классификатора взяли, например, k-NN (метод k-ближайших соседей).
	•	Для k-NN важно масштабировать признаки. Затем мы перебирали гиперпараметр n_neighbors (например, [3, 5, 15, 50]) и тип весов (uniform, distance).
	•	По итогам GridSearchCV лучший вариант мог давать Accuracy ~83–84% и AUC-ROC ~0.88–0.89 (чуть ниже, чем у логистической регрессии с регуляризацией).

14. Как сравнили классификаторы и к каким выводам пришли?

Вопрос (из методички, пункт 12): «Оцініть якість моделей на тестовій вибірці…».
Ответ:
	•	Сравнили логистическую регрессию (с оптимальным C) и k-NN на тестовой выборке по метрикам AUC-ROC, Accuracy, F1.
	•	Логистическая регрессия показала AUC-ROC около ~0.90, а k-NN — около ~0.88. Точность у логистической регрессии тоже чуть выше.
	•	Сильные стороны LR: интерпретируемость, скорость обучения и предсказания, хорошее качество. Сильные стороны k-NN: простая идея, неплохо работает при небольшом числе признаков, но медленнее на больших данных.

Итоговый вывод

	1.	Подготовка данных (обработка пропусков, кодирование категорий, масштабирование) — ключевой шаг для корректного обучения.
	2.	Классы немного несбалансированы (75% / 25%), поэтому стоит смотреть не только на Accuracy, но и на AUC-ROC, F1 и прочие метрики.
	3.	Без регуляризации модель может показывать хорошие метрики, но иметь риск переобучения (слишком большие веса).
	4.	Кросс-валидация даёт более стабильную оценку качества и помогает подбирать гиперпараметры (параметр C).
	5.	Регуляризация (L2) помогает «сжать» веса и сделать модель более устойчивой, при этом качество либо улучшается, либо остаётся примерно таким же, но с меньшим переобучением.
	6.	При сравнении с другим классификатором (k-NN) логистическая регрессия (с оптимальным C) обычно выигрывает по AUC-ROC и времени работы.

Таким образом, модель логистической регрессии с учётом грамотной предобработки данных, регуляризации и подобранного параметра C оказывается наиболее эффективной для решения данной задачи классификации.